(1641)/(1641+87)
(377)/(377+46)
(1641)/(1641+46)
(2*0.9727327*0.9496528)/(0.9496528+0.9727327)
cartModelPred <- predict(cartModel,newdata = test,type = "class")
cartModel <- rpart(suspicious~., method = "class",data = train)
prp(cartModel)
fancyRpartPlot(cartModel,type = 2, cex = 0.6)
cartModelPred <- predict(cartModel,newdata = test,type = "class")
table(cartModelPred,test$suspicious)
(1625+251)/(1625+251+213+62)
(1625)/(1625+62)
(1625)/(1625+213)
251/(251+62)
(2*0.9632484*0.8841132)/(0.8841132+0.9632484)
logRegModelPred <- predict(logRegModel,newdata = test,type = "response")
logRegModel <- glm(suspicious~., family = "binomial",data = train)
logRegModelPred <- predict(logRegModel,newdata = test,type = "response")
table(logRegModelPred>0.5,test$suspicious)
((354+1614)/(354+1614+110+73))
(1614)/(1614+110)
1614/(1614+73)
354/(354+1614)
354/(354+110)
(2*(0.9361949*0.9567279))/(0.9567279+0.9361949)
cartModelROCPred <- prediction(predict(cartModel,type = "prob")[,2],train$suspicious)
plot(performance(cartModelROCPred,"tpr","fpr"),colorize = TRUE, text.adj = c(-0.2,1.7),main = "ROC curve for Classification Trees")
as.numeric(performance(cartModelROCPred, "auc")@y.values)
table(rfModelPred, test$suspicious)
(1641+377)/(1641+377+87+46)
algoNames <- c("Logistic Regression","Classification Trees","Random Forests","Naive Bayes","Gradient Boost","Optimized Classification Trees")
nbModelPred <- predict(nbModel, newdata = test)
table(nbModelPred,test$suspicious)
(1457+361)/sum(table(nbModelPred,test$suspicious))
auc <-as.numeric(c(0.8598295,0.8241452,0.9715824,0.8240945,0.9625293))
accuracy <- as.numeric(c(0.9149233,0.8721525,0.9381683,0.8451883,0.9046955))
precision <- as.numeric(c(0.9361949,0.9632484,0.9727327,0.8636633,0.9673977))
recall <- as.numeric(c(0.9567279,0.8841132,0.9496528,0.9339744,0.9158249))
specificity <- as.numeric(c(0.762931,0.8019169,0.891253,0.6108291,0.8509485))
f1Score <- as.numeric(c(0.94635,0.9219858,0.9610542,0.8974438,0.9409051))
algoNames <- c("Logistic Regression","Classification Trees","Random Forests","Naive Bayes","Gradient Boost")
algoDF <- data.frame(auc,accuracy,precision,recall,specificity,f1Score)
colnames(algoDF) <- algoNames
head(algoDF)
rownames(algoDF) <- c("auc","accuracy","precision","recall","specificity","f1score")
rownames(algoDF) <- c("auc","accuracy","precision","recall","specificity","f1score")
rownames(algoDF) <- algoNames
colnames(algoDF) <- c("auc","accuracy","precision","recall","specificity","f1score")
head(algoDF)
?write.csv
write.csv(file = "metrics.csv")
write.csv(algoDF,file = "metrics.csv")
algoDF <- read.csv("metrics.csv")
str(algoDF)
head(algoDF)
library(tidyverse)
library(RColorBrewer)
ggplot(data = algoDF,mapping = aes(x = X, y = auc)) + geom_point()
ggplot(data = algoDF,mapping = aes(x = X, y = auc)) + geom_point() + geom_line()
ggplot(data = algoDF,mapping = aes(x = X, y = auc)) + geom_point()
ggplot(data = algoDF,mapping = aes(x = X, y = auc)) + geom_point() + geom_smooth()
ggplot(data = algoDF,mapping = aes(x = X, y = auc)) + geom_point()
ggplot(data = algoDF,mapping = aes(x = X, y = auc)) + geom_point() + geom_line()
ggplot(data = algoDF,mapping = aes(x = X, y = auc)) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = auc,fill = X)) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = auc,fill = auc)) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = auc)) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = auc)) + geom_point(aes(fill = as.factor(X))) + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = auc)) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = accuracy)) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = precision)) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = recall)) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = specificity)) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score)) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = auc)) + geom_col()
ggplot(data = algoDF,mapping = aes(x = X, y = auc)) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = accuracy)) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = precision)) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = recall)) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = specificity)) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score)) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score,main = "title")) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score,title = "title")) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score,title = "f1Score across the algorithms")) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score,title = "f1Score across the algorithms")) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score,title = "f1Score across the algorithms")) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score)) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score,title = "f1Score across the algorithms")) + geom_point() + geom_line(aes(group = 1))
?ggplot
ggplot(data = algoDF,mapping = aes(x = X, y = recall)) + geom_point(colour = X) + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = recall),colour = X) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score,main = "f1Score across the algorithms")) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score,title = "f1Score across the algorithms")) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score,label = "f1Score across the algorithms")) + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score),label = "f1Score across the algorithms") + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score),label = "f1Score across the algorithms") + geom_point() + geom_line(aes(group = 1))
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("test")
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("f1score")
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("f1scores per algorithm")
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("f1scores for all algorithm")
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("f1scores for all algorithm") + xlab("")
ggplot(data = algoDF,mapping = aes(x = X, y = specificity)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("Specificity for all algorithms") + xlab("")
ggplot(data = algoDF,mapping = aes(x = X, y = recall)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("Recall for all algorithms") + xlab("")
ggplot(data = algoDF,mapping = aes(x = X, y = precision)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("Precision for all algorithms") + xlab("")
ggplot(data = algoDF,mapping = aes(x = X, y = accuracy)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("Accuracy for all algorithms") + xlab("")
ggplot(data = algoDF,mapping = aes(x = X, y = auc)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("AUC(Area under curve) for all algorithms") + xlab("")
plot(performance(nbPredNew,"tpr","fpr"), colorize = TRUE, text.adj = c(-0.2,1.7),main = "ROC curve for Naive Bayes")
plot(performance(ROCrf,"tpr","fpr"),colorize = TRUE, text.adj = c(-0.2,1.7),main = "ROC curve for Random Forests")
ROCrf <- prediction(predict(rfModel,type = "prob")[,2],train$suspicious)
plot(performance(ROCrf,"tpr","fpr"),colorize = TRUE, text.adj = c(-0.2,1.7),main = "ROC curve for Random Forests")
plot(performance(cartModelROCPred,"tpr","fpr"),colorize = TRUE, text.adj = c(-0.2,1.7),main = "ROC curve for Classification Trees")
ggplot(data = algoDF,mapping = aes(x = X, y = auc)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("AUC(Area under curve) for all algorithms") + xlab("")
ggplot(data = algoDF,mapping = aes(x = X, y = accuracy)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("Accuracy for all algorithms") + xlab("")
ggplot(data = algoDF,mapping = aes(x = X, y = precision)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("Precision for all algorithms") + xlab("")
ggplot(data = algoDF,mapping = aes(x = X, y = recall)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("Recall for all algorithms") + xlab("")
ggplot(data = algoDF,mapping = aes(x = X, y = specificity)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("Specificity for all algorithms") + xlab("")
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("f1scores for all algorithm") + xlab("")
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("f1scores for all algorithm") + xlab("") + scale_y_continuous(labels = scientific)
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("f1scores for all algorithm") + xlab("") + scale_y_continuous(labels = "scientific")
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("f1scores for all algorithm") + xlab("")
ggplot(data = algoDF,mapping = aes(x = X, y = f1Score)) + geom_point() + geom_line(aes(group = 1)) + ggtitle("f1scores for all algorithms") + xlab("")
?ROCR
?prediction
tweets <- read.csv("Data/tweets.csv",stringsAsFactors = FALSE)
tweets <- read.csv("Data/labeled_data.csv",stringsAsFactors = FALSE)
head(tweets)
class(tweets$class)
tweets$class <- as.character(tweets$class)
class(tweets$class)
head(tweets)
tweets$class[tweets$class==0] <- "suspicious"
tweets$class[tweets$class==1 | tweets$class==2] <- "safe"
head(tweets)
summary(tweets$class)
tweets$class <- as.factor(tweets$class)
table(tweets$class)
library(tm)
library(wordcloud)
library(SnowballC)
library(RColorBrewer)
tweetsCorpus <- Corpus(VectorSource(tweets$tweet))
tweetsCorpus <- tm_map(tweetsCorpus,tolower)
tweetsCorpus <- tm_map(tweetsCorpus,removeNumbers)
tweetsCorpus <- tm_map(tweetsCorpus,removePunctuation)
tweetsCorpus <- tm_map(tweetsCorpus,removeWords,c(as.character(stop_words)))
tweetsCorpus <- tm_map(tweetsCorpus,stemDocument)
wordcloud(tweetsCorpus, min.freq = 75,random.order = FALSE,random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(tweetsCorpus, min.freq = 100,random.order = FALSE,random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(tweetsCorpus, min.freq = 20,random.order = FALSE,random.color = FALSE,colors = brewer.pal(9,"Spectral"))
frequencies = DocumentTermMatrix(tweetsCorpus)
frequencies
inspect(frequencies[1000:1005,505:515])
sparse = removeSparseTerms(frequencies, 0.995)
sparse
tweetsSparse <- as.data.frame(as.matrix(sparse))
colnames(tweetsSparse) <- make.names(colnames(tweetsSparse))
tweetsSparse$suspicious <- tweetsCorpus$suspicious
tweetsSparse <- as.data.frame(as.matrix(sparse))
sparse = removeSparseTerms(frequencies, 0.995)
sparse
tweetsSparse <- as.data.frame(as.matrix(sparse))
colnames(tweetsSparse) <- make.names(colnames(tweetsSparse))
tweetsSparse$suspicious <- tweets$class
wordcloud(tweetsSparse)
class(sparse)
wordcloud(frequencies)
summary(spam)
summary(deceptiveOpinion)
str(spam)
spam <- spam[, 1:2]
str(deceptiveOpinion)
deceptiveOpinion <- deceptiveOpinion[, c(1, 5)]
#spam$v2 <- as.factor(spam$v2)
#class(spam$v2)
#deceptiveOpinion$deceptive <- as.factor(deceptiveOpinion$deceptive)
colnames(spam) <- c("suspicious", "text")
colnames(deceptiveOpinion) <- c("suspicious", "text")
summary(deceptiveOpinion)
#deceptiveOpinion <- deceptiveOpinion %>% filter(suspicious=="deceptive") %>% mutate(suspicious="spam")
deceptiveOpinion$suspicious[deceptiveOpinion$suspicious=="deceptive"] <- "suspicious"
deceptiveOpinion$suspicious[deceptiveOpinion$suspicious=="truthful"] <- "safe"
spam$suspicious[spam$suspicious=="spam"] <- "suspicious"
spam$suspicious[spam$suspicious=="ham"] <- "safe"
suspDF <- rbind(spam,deceptiveOpinion)
suspDF$suspicious <- as.factor(suspDF$suspicious)
summary(suspDF)
finalDF <- rbind(spam,deceptiveOpinion, tweets)
names(tweets)
finalDF <- rbind(spam,deceptiveOpinion, tweets[,6:7])
tweets[1:2,6:7]
tweetsFinal <- tweets[,6:7]
head(tweetsFinal)
colnames(tweetsFinal) <- c("suspicious","text")
head(tweetsFinal)
finalDF <- rbind(spam,deceptiveOpinion, tweetsFinal)
tweetsCorpus <- Corpus(VectorSource(finalDF$text))
finalCorpus <- Corpus(VectorSource(finalDF$text))
finalCorpus <- tm_map(finalCorpus,tolower)
finalCorpus <- tm_map(finalCorpus,removeNumbers)
finalCorpus <- tm_map(finalCorpus,removePunctuation)
finalCorpus <- tm_map(finalCorpus,removeWords,c(as.character(stop_words)))
finalCorpus <- tm_map(finalCorpus,stemDocument)
wordcloud(finalCorpus)
wordcloud(finalCorpus,min.freq = 100,max.words = 300,random.order = FALSE)
wordcloud(finalCorpus,min.freq = 100,max.words = 300,random.order = FALSE,scale = c(1,3))
wordcloud(finalCorpus,min.freq = 100,max.words = 300,random.order = FALSE,scale = c(0.5,2))
wordcloud(finalCorpus,min.freq = 40,max.words = 300,random.order = FALSE,scale = c(0.5,2))
set.seed(100)
wordcloud(finalCorpus,min.freq = 40,max.words = 300,random.order = FALSE,scale = c(0.5,2))
wordcloud(finalCorpus,min.freq = 40,max.words = 300,random.order = FALSE,scale = c(0.5,2))
wordcloud(finalCorpus,min.freq = 40,max.words = 300,random.order = FALSE,scale = c(0.25,2))
wordcloud(finalCorpus,min.freq = 40,max.words = 300,random.order = FALSE,scale = c(0.5,1.25))
wordcloud(finalCorpus,min.freq = 40,max.words = 300,random.order = FALSE,scale = c(0.5,1.25),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
?wordcloud
wordcloud(finalCorpus,min.freq = 100,random.order = FALSE,scale = c(0.5,1.25),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus,min.freq = 100,random.order = FALSE,scale = c(0.5,1),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus,min.freq = 100,max.words = 200,random.order = FALSE,scale = c(0.5,1),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
dim(finalCorpus)
dim(finalDF)
wordcloud(finalCorpus,min.freq = 500,max.words = 200,random.order = FALSE,scale = c(0.5,1),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus,min.freq = 500,max.words = 250,random.order = FALSE,scale = c(0.5,1),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
library(tidyverse)
finalCorpus <- Corpus(VectorSource(finalDF$text))
finalCorpus <- tm_map(finalCorpus,tolower)
finalCorpus <- tm_map(finalCorpus,removeNumbers)
finalCorpus <- tm_map(finalCorpus,removePunctuation)
finalCorpus <- tm_map(finalCorpus,removeWords,stopwords("english"))
finalCorpus <- tm_map(finalCorpus,removeWords,c(as.character(stop_words)))
finalCorpus <- tm_map(finalCorpus,stemDocument)
wordcloud(finalCorpus,min.freq = 500,max.words = 250,random.order = FALSE,scale = c(0.5,1),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
library(tidyverse)
wordcloud(finalCorpus,min.freq = 300,max.words = 250,random.order = FALSE,scale = c(0.5,1),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus,min.freq = 300,max.words = 300,random.order = FALSE,scale = c(0.5,1),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus,min.freq = 500,max.words = 300,random.order = FALSE,scale = c(0.5,1),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus,min.freq = 450,max.words = 300,random.order = FALSE,scale = c(0.5,1),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus,min.freq = 350,max.words = 300,random.order = FALSE,scale = c(0.5,1),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
finalWords %>% unnest_tokens(word,text)
finalDF %>% unnest_tokens(word,text)
finalDF %>% unnest_tokens(word,text) %>% group_by(suspicious)
finalDFTokens <- finalDF %>% unnest_tokens(word,text) %>% group_by(suspicious)
tail(finalDFTokens)
head(finalDFTokens)
finalDFTokens <-
finalDFTokens <- finalDF %>% unnest_tokens(word,text)
tail(finalDFTokens)
head(finalDFTokens)
totalWords <- finalDFTokens %>% group_by(suspicious) %>% summarize(total = sum(n))
finalDFTokens <- finalDF %>% unnest_tokens(word,text) %>% count(suspicious,word,sort = TRUE) %>% ungroup()
totalWords <- finalDFTokens %>% group_by(suspicious) %>% summarize(total = sum(n))
finalDFTokens <- left_join(finalDFTokens,totalWords)
finalDFTokens
finalDFTokens <- finalDFTokens %>% bind_tf_idf(word,suspicious,n)
finalDFTokens
finalDFTokens %>% select(-total) %>% arrange(desc(tf_idf))
finalDFTokens %>% arrange(desc(tf_idf)) %>% mutate(word = factor(word,levels = rev(unique(word)))) %>% group_by(suspicious) %>% top_n(15) %>% ungroup %>% ggplot(aes(word,tf_idf,fill = suspicious))+geom_col(show.legend = FALSE)+labs(x = NULL,y = "tf-idf")+facet_wrap(~suspicious,ncol = 2,scales = "free")+coord_flip()
finalDFTokens <- finalDF %>% unnest_tokens(word,text) %>% anti_join(stop_words) %>% count(suspicious,word,sort = TRUE) %>% ungroup()
totalWords <- finalDFTokens %>% group_by(suspicious) %>% summarize(total = sum(n))
finalDFTokens <- left_join(finalDFTokens,totalWords)
finalDFTokens
finalDFTokens <- finalDFTokens %>% bind_tf_idf(word,suspicious,n)
finalDFTokens
finalDFTokens %>% select(-total) %>% arrange(desc(tf_idf))
finalDFTokens %>% arrange(desc(tf_idf)) %>% mutate(word = factor(word,levels = rev(unique(word)))) %>% group_by(suspicious) %>% top_n(15) %>% ungroup %>% ggplot(aes(word,tf_idf,fill = suspicious))+geom_col(show.legend = FALSE)+labs(x = NULL,y = "tf-idf")+facet_wrap(~suspicious,ncol = 2,scales = "free")+coord_flip()
finalDFTokens %>% arrange(desc(tf_idf)) %>% mutate(word = factor(word,levels = rev(unique(word)))) %>% group_by(suspicious) %>% top_n(20) %>% ungroup %>% ggplot(aes(word,tf_idf,fill = suspicious))+geom_col(show.legend = FALSE)+labs(x = NULL,y = "tf-idf")+facet_wrap(~suspicious,ncol = 2,scales = "free")+coord_flip()
finalDFTokens %>% arrange(desc(tf_idf)) %>% mutate(word = factor(word,levels = rev(unique(word)))) %>% group_by(suspicious) %>% top_n(40) %>% ungroup %>% ggplot(aes(word,tf_idf,fill = suspicious))+geom_col(show.legend = FALSE)+labs(x = NULL,y = "tf-idf")+facet_wrap(~suspicious,ncol = 2,scales = "free")+coord_flip()
spam <-
read.csv(
"C:/Users/Nishank/Desktop/SNU/Project/Suspicious/Data/spam.csv",
stringsAsFactors = FALSE
)
deceptiveOpinion <-
read.csv(
"C:/Users/Nishank/Desktop/SNU/Project/Suspicious/Data/deceptive-opinion.csv",
stringsAsFactors = FALSE
)
library(tidyverse)
summary(spam)
summary(deceptiveOpinion)
str(spam)
spam <- spam[, 1:2]
str(deceptiveOpinion)
deceptiveOpinion <- deceptiveOpinion[, c(1, 5)]
#spam$v2 <- as.factor(spam$v2)
#class(spam$v2)
#deceptiveOpinion$deceptive <- as.factor(deceptiveOpinion$deceptive)
colnames(spam) <- c("suspicious", "text")
colnames(deceptiveOpinion) <- c("suspicious", "text")
summary(deceptiveOpinion)
#deceptiveOpinion <- deceptiveOpinion %>% filter(suspicious=="deceptive") %>% mutate(suspicious="spam")
deceptiveOpinion$suspicious[deceptiveOpinion$suspicious=="deceptive"] <- "suspicious"
deceptiveOpinion$suspicious[deceptiveOpinion$suspicious=="truthful"] <- "safe"
spam$suspicious[spam$suspicious=="spam"] <- "suspicious"
spam$suspicious[spam$suspicious=="ham"] <- "safe"
suspDF <- rbind(spam,deceptiveOpinion)
suspDF$suspicious <- as.factor(suspDF$suspicious)
summary(suspDF)
tweets <- read.csv("Data/labeled_data.csv",stringsAsFactors = FALSE)
head(tweets)
class(tweets$class)
tweets$class <- as.character(tweets$class)
tweets$class[tweets$class==0] <- "suspicious"
tweets$class[tweets$class==1 | tweets$class==2] <- "safe"
summary(tweets$class)
tweets$class <- as.factor(tweets$class)
table(tweets$class)
library(tm)
library(wordcloud)
library(SnowballC)
library(RColorBrewer)
tweetsFinal <- tweets[,6:7]
colnames(tweetsFinal) <- c("suspicious","text")
finalDF <- rbind(spam,deceptiveOpinion, tweetsFinal)
finalCorpus <- Corpus(VectorSource(finalDF$text))
finalCorpus <- tm_map(finalCorpus,tolower)
finalCorpus <- tm_map(finalCorpus,removeNumbers)
finalCorpus <- tm_map(finalCorpus,removePunctuation)
finalCorpus <- tm_map(finalCorpus,removeWords,stopwords("english"))
finalCorpus <- tm_map(finalCorpus,removeWords,c(as.character(stop_words)))
finalCorpus <- tm_map(finalCorpus,stemDocument)
#wordcloud(tweetsCorpus, min.freq = 20,random.order = FALSE,random.color = FALSE,colors = brewer.pal(9,"Spectral"))
frequencies = DocumentTermMatrix(tweetsCorpus)
frequencies
inspect(frequencies[1000:1005,505:515])
findFreqTerms(frequencies, lowfreq=20)
sparse = removeSparseTerms(frequencies, 0.995)
sparse
tweetsSparse <- as.data.frame(as.matrix(sparse))
colnames(tweetsSparse) <- make.names(colnames(tweetsSparse))
tweetsSparse$suspicious <- tweets$class
class(sparse)
set.seed(100)
wordcloud(finalCorpus,min.freq = 350,max.words = 300,random.order = FALSE,scale = c(0.5,1),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
frequencies = DocumentTermMatrix(suspText)
frequencies
inspect(frequencies[1000:1005,505:515])
findFreqTerms(frequencies, lowfreq=20)
sparse = removeSparseTerms(frequencies, 0.995)
sparse
suspSparse <- as.data.frame(as.matrix(sparse))
colnames(suspSparse) <- make.names(colnames(suspSparse))
suspSparse$suspicious <- suspDF$suspicious
spam <-
read.csv(
"C:/Users/Nishank/Desktop/SNU/Project/Suspicious/Data/spam.csv",
stringsAsFactors = FALSE
)
deceptiveOpinion <-
read.csv(
"C:/Users/Nishank/Desktop/SNU/Project/Suspicious/Data/deceptive-opinion.csv",
stringsAsFactors = FALSE
)
library(tidyverse)
summary(spam)
summary(deceptiveOpinion)
str(spam)
spam <- spam[, 1:2]
str(deceptiveOpinion)
deceptiveOpinion <- deceptiveOpinion[, c(1, 5)]
#spam$v2 <- as.factor(spam$v2)
#class(spam$v2)
#deceptiveOpinion$deceptive <- as.factor(deceptiveOpinion$deceptive)
colnames(spam) <- c("suspicious", "text")
colnames(deceptiveOpinion) <- c("suspicious", "text")
summary(deceptiveOpinion)
#deceptiveOpinion <- deceptiveOpinion %>% filter(suspicious=="deceptive") %>% mutate(suspicious="spam")
deceptiveOpinion$suspicious[deceptiveOpinion$suspicious=="deceptive"] <- "suspicious"
deceptiveOpinion$suspicious[deceptiveOpinion$suspicious=="truthful"] <- "safe"
spam$suspicious[spam$suspicious=="spam"] <- "suspicious"
spam$suspicious[spam$suspicious=="ham"] <- "safe"
suspDF <- rbind(spam,deceptiveOpinion)
suspDF$suspicious <- as.factor(suspDF$suspicious)
summary(suspDF)
library(tm)
suspText <- Corpus(VectorSource(suspDF$text))
suspText <- tm_map(suspText,tolower)
suspText <- tm_map(suspText,removePunctuation)
suspText <- tm_map(suspText,removeNumbers)
suspText <- tm_map(suspText,removeWords,stopwords("english"))
suspText <- tm_map(suspText,stemDocument)
library(tidytext)
suspText <- tm_map(suspText,removeWords,c(as.character(stop_words)))
library(wordcloud)
wordcloud(suspText, min.freq = 75,random.order = FALSE,random.color = FALSE,colors = brewer.pal(9,"Spectral"))
library(rpart)
library(rpart.plot)
library(caret)
library(randomForest)
library(caTools)
frequencies = DocumentTermMatrix(suspText)
frequencies
inspect(frequencies[1000:1005,505:515])
findFreqTerms(frequencies, lowfreq=20)
sparse = removeSparseTerms(frequencies, 0.995)
sparse
suspSparse <- as.data.frame(as.matrix(sparse))
colnames(suspSparse) <- make.names(colnames(suspSparse))
suspSparse$suspicious <- suspDF$suspicious
tweets <- read.csv("Data/labeled_data.csv",stringsAsFactors = FALSE)
head(tweets)
class(tweets$class)
tweets$class <- as.character(tweets$class)
tweets$class[tweets$class==0] <- "suspicious"
tweets$class[tweets$class==1 | tweets$class==2] <- "safe"
summary(tweets$class)
tweets$class <- as.factor(tweets$class)
table(tweets$class)
library(tm)
library(wordcloud)
library(SnowballC)
library(RColorBrewer)
tweetsFinal <- tweets[,6:7]
colnames(tweetsFinal) <- c("suspicious","text")
finalDF <- rbind(spam,deceptiveOpinion, tweetsFinal)
finalCorpus <- Corpus(VectorSource(finalDF$text))
finalCorpus <- tm_map(finalCorpus,tolower)
finalCorpus <- tm_map(finalCorpus,removeNumbers)
finalCorpus <- tm_map(finalCorpus,removePunctuation)
finalCorpus <- tm_map(finalCorpus,removeWords,stopwords("english"))
finalCorpus <- tm_map(finalCorpus,removeWords,c(as.character(stop_words)))
finalCorpus <- tm_map(finalCorpus,stemDocument)
#wordcloud(tweetsCorpus, min.freq = 20,random.order = FALSE,random.color = FALSE,colors = brewer.pal(9,"Spectral"))
frequencies = DocumentTermMatrix(tweetsCorpus)
frequencies
inspect(frequencies[1000:1005,505:515])
findFreqTerms(frequencies, lowfreq=20)
sparse = removeSparseTerms(frequencies, 0.995)
sparse
tweetsSparse <- as.data.frame(as.matrix(sparse))
colnames(tweetsSparse) <- make.names(colnames(tweetsSparse))
tweetsSparse$suspicious <- tweets$class
class(sparse)
set.seed(100)
wordcloud(finalCorpus,min.freq = 350,max.words = 300,random.order = FALSE,scale = c(0.5,1),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
library(tidyverse)
finalDFTokens <- finalDF %>% unnest_tokens(word,text) %>% anti_join(stop_words) %>% count(suspicious,word,sort = TRUE) %>% ungroup()
tail(finalDFTokens)
head(finalDFTokens)
totalWords <- finalDFTokens %>% group_by(suspicious) %>% summarize(total = sum(n))
finalDFTokens <- left_join(finalDFTokens,totalWords)
finalDFTokens
finalDFTokens <- finalDFTokens %>% bind_tf_idf(word,suspicious,n)
finalDFTokens
finalDFTokens %>% select(-total) %>% arrange(desc(tf_idf))
finalDFTokens %>% arrange(desc(tf_idf)) %>% mutate(word = factor(word,levels = rev(unique(word)))) %>% group_by(suspicious) %>% top_n(40) %>% ungroup %>% ggplot(aes(word,tf_idf,fill = suspicious))+geom_col(show.legend = FALSE)+labs(x = NULL,y = "tf-idf")+facet_wrap(~suspicious,ncol = 2,scales = "free")+coord_flip()
wordcloud(finalCorpus,min.freq = 350,max.words = 300,random.order = FALSE,scale = c(0.5,1),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus,min.freq = 350,max.words = 300,random.order = FALSE,scale = c(1,3),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus,min.freq = 350,max.words = 300,random.order = FALSE,scale = c(0.5,2),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus,min.freq = 350,max.words = 200,random.order = FALSE,scale = c(0.5,2),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus,min.freq = 450,max.words = 200,random.order = FALSE,scale = c(0.5,2),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus,min.freq = 450,max.words = 100,random.order = FALSE,scale = c(0.5,2),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus,min.freq = 500,max.words = 100,random.order = FALSE,scale = c(0.5,2),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus,min.freq = 500,max.words = 100,random.order = FALSE,scale = c(0.5,1.5),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus,min.freq = 550,max.words = 100,random.order = FALSE,scale = c(0.5,1.5),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus, min.freq = 550,random.order = FALSE,random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus, min.freq = 550,random.order = FALSE,random.color = FALSE,colors = brewer.pal(9,"Spectral"),scale = c(0.5,2))
wordcloud(finalCorpus, min.freq = 550,random.order = FALSE,random.color = FALSE,colors = brewer.pal(9,"Spectral"),scale = c(2,0.5))
wordcloud(finalCorpus, min.freq = 550,random.order = FALSE,random.color = FALSE,colors = brewer.pal(9,"Spectral"),scale = c(3,1))
wordcloud(finalCorpus, min.freq = 400,random.order = FALSE,random.color = FALSE,colors = brewer.pal(9,"Spectral"),scale = c(3,1))
wordcloud(finalCorpus,min.freq = 350,max.words = 300,random.order = FALSE,scale = c(1,3),random.color = FALSE,colors = brewer.pal(9,"Spectral"))
wordcloud(finalCorpus, min.freq = 400,random.order = FALSE,random.color = FALSE,colors = brewer.pal(9,"Spectral"),scale = c(3,1))
finalDFTokens <- finalDF %>% unnest_tokens(word,text) %>% anti_join(stop_words) %>% count(suspicious,word,sort = TRUE) %>% ungroup()
totalWords <- finalDFTokens %>% group_by(suspicious) %>% summarize(total = sum(n))
finalDFTokens <- left_join(finalDFTokens,totalWords)
finalDFTokens
finalDFTokens <- finalDFTokens %>% bind_tf_idf(word,suspicious,n)
finalDFTokens
finalDFTokens %>% select(-total) %>% arrange(desc(tf_idf))
finalDFTokens %>% arrange(desc(tf_idf)) %>% mutate(word = factor(word,levels = rev(unique(word)))) %>% group_by(suspicious) %>% top_n(40) %>% ungroup %>% ggplot(aes(word,tf_idf,fill = suspicious))+geom_col(show.legend = FALSE)+labs(x = NULL,y = "tf-idf")+facet_wrap(~suspicious,ncol = 2,scales = "free")+coord_flip()
?removeSparseTerms
sparse = removeSparseTerms(frequencies, 0.15)
sparse
tweetsSparse <- as.data.frame(as.matrix(sparse))
colnames(tweetsSparse) <- make.names(colnames(tweetsSparse))
tweetsSparse$suspicious <- tweets$class
class(sparse)
set.seed(100)
tweets <- read.csv("Data/labeled_data.csv",stringsAsFactors = FALSE)
head(tweets)
class(tweets$class)
tweets$class <- as.character(tweets$class)
tweets$class[tweets$class==0] <- "suspicious"
tweets$class[tweets$class==1 | tweets$class==2] <- "safe"
summary(tweets$class)
tweets$class <- as.factor(tweets$class)
table(tweets$class)
library(tm)
library(wordcloud)
library(SnowballC)
library(RColorBrewer)
tweetsFinal <- tweets[,6:7]
colnames(tweetsFinal) <- c("suspicious","text")
finalDF <- rbind(spam,deceptiveOpinion, tweetsFinal)
finalCorpus <- Corpus(VectorSource(finalDF$text))
finalCorpus <- tm_map(finalCorpus,tolower)
finalCorpus <- tm_map(finalCorpus,removeNumbers)
finalCorpus <- tm_map(finalCorpus,removePunctuation)
finalCorpus <- tm_map(finalCorpus,removeWords,stopwords("english"))
finalCorpus <- tm_map(finalCorpus,removeWords,c(as.character(stop_words)))
finalCorpus <- tm_map(finalCorpus,stemDocument)
#wordcloud(tweetsCorpus, min.freq = 20,random.order = FALSE,random.color = FALSE,colors = brewer.pal(9,"Spectral"))
frequencies = DocumentTermMatrix(tweetsCorpus)
frequencies
inspect(frequencies[1000:1005,505:515])
findFreqTerms(frequencies, lowfreq=20)
sparse = removeSparseTerms(frequencies, 0.15)
sparse
tweetsSparse <- as.data.frame(as.matrix(sparse))
colnames(tweetsSparse) <- make.names(colnames(tweetsSparse))
tweetsSparse$suspicious <- tweets$class
class(sparse)
set.seed(100)
wordcloud(finalCorpus, min.freq = 400,random.order = FALSE,random.color = FALSE,colors = brewer.pal(9,"Spectral"),scale = c(3,1))
